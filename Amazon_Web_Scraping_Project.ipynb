{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Amazon-Web-Scraping-Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOi1Z/YZeOF6zzfyVJqpTYi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkashPushp/Amazon-Data-Extraction-Project/blob/main/Amazon_Web_Scraping_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIZz8lJN8eJu"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Amazon Web Scraping Using Python\n",
        "Description\n",
        "-Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It’s a useful technique for creating datasets for research and learning. \n",
        "-Amazon.com is a vast internet based enterprise that sells books, music,movies,housewares,electronics,toys and many other goods online. it is the world's largest online retailor and prominent cloud service provider.\n",
        "# Problem statement\n",
        "My goal for this project to get data like Book Name, Price,Author,Ratings,Availibility,Rating Count, Date(timestamp) of certain product from amazon.com using python and the libraries like BeautifulSoap.\n",
        "\n",
        "# Project Outline:\n",
        " - We are going to scrap from website 'https://www.amazon.in/dp/8194790832/ref=s9_acsd_hps_bw_c2_x_3_i?pf_rd_m=A1K21FY43GMZF8&pf_rd_s=merchandised-search-7&pf_rd_r=QBKNEYYTKXJBNNPNE2G8&pf_rd_t=101&pf_rd_p=7482c79b-44d8-4499-93ae-28d5be5ebb9c&pf_rd_i=976389031'.\n",
        " -We'll get a list of topics like Book Name, Price,Author,Ratings,Availibility,Rating Count, Date(timestamp) etc.\n",
        " - We'll create a CSV file in excel sheet format.\n",
        " # Methods used\n",
        "-use requests to downlaod the page\n",
        "-user BS4 to parse and extract information\n",
        "-convert to a Pandas dataframe\n",
        " \n",
        "#Contributor Akash Pushp(Data Analyst)\n"
      ],
      "metadata": {
        "id": "gamh9tX8AMsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the request library to download the web page."
      ],
      "metadata": {
        "id": "NU4beb4zCkCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " # Import libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import smtplib"
      ],
      "metadata": {
        "id": "ePMeypvrCiLk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Connecting to website and extracting Data"
      ],
      "metadata": {
        "id": "o-L4oBYBPqD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Connect to websites and Pull in Data\n",
        "URL ='https://www.amazon.in/dp/8194790832/ref=s9_acsd_hps_bw_c2_x_3_i?pf_rd_m=A1K21FY43GMZF8&pf_rd_s=merchandised-search-7&pf_rd_r=QBKNEYYTKXJBNNPNE2G8&pf_rd_t=101&pf_rd_p=7482c79b-44d8-4499-93ae-28d5be5ebb9c&pf_rd_i=976389031'\n",
        "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\",\"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\"DNT\":\"1\",\"Connection\":\"close\",\"Upgrade-Insecure-Requests\":\"1\"}\n",
        "page = requests.get(URL, headers=headers)\n",
        "\n",
        "soup1 = BeautifulSoup(page.content, \"lxml\")\n",
        "\n",
        "soup2 = BeautifulSoup(soup1.prettify(), \"lxml\")\n",
        "\n",
        "\n",
        "\n",
        "title = soup2.find(\"span\",attrs={\"id\":\"productTitle\"})\n",
        "title_value = title.string\n",
        "book_name = title_value.strip().replace(',','')\n",
        "price = soup2.find(\"span\", attrs={\"class\":\"a-size-base a-color-price a-color-price\"}).string.strip().replace(',','')\n",
        "Author = soup2.find(\"a\", attrs={\"data-asin\":\"B001HCYPOC\"}).string.strip().replace(',','')\n",
        "ratings = soup2.find(\"span\", attrs={\"class\":\"a-icon-alt\"}).string.strip().replace(',','')\n",
        "Availibility=soup2.find(\"span\", attrs={\"class\":\"a-size-medium a-color-success\"}).string.strip().replace(',','')\n",
        "rating_count = soup2.find(\"span\",attrs={\"id\":\"acrCustomerReviewText\"}).string.strip().replace(',','')\n",
        "\n",
        "print(book_name)\n",
        "print(price)\n",
        "print(Author)\n",
        "print(ratings)\n",
        "print(Availibility)\n",
        "print(rating_count)\n",
        "                 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydiPEqVMusWY",
        "outputId": "1589b34e-b12a-4445-89fc-c7f1eeaffcc6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Power of Your Subconscious Mind\n",
            "₹115.00\n",
            "Joseph Murphy\n",
            "4.5 out of 5 stars\n",
            "In stock.\n",
            "58149 ratings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating a Timestamp for your output to track when data was collected."
      ],
      "metadata": {
        "id": "PJYiIoW_P8pN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Timestamp for your output to track when data was collected\n",
        "\n",
        "import datetime\n",
        "\n",
        "today = datetime.date.today()\n",
        "\n",
        "print(today)\n"
      ],
      "metadata": {
        "id": "9uMDOe3yyOG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8146e1a-15d8-4322-e312-16d18d3b9576"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating CSV file."
      ],
      "metadata": {
        "id": "sLK9zQfeQPQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CSV and write headers and data into the file\n",
        "\n",
        "import csv \n",
        "\n",
        "header = ['Book Name', 'Price','Author','Ratings','Availibility','Rating Count', 'Date']\n",
        "data = [book_name, price, Author, ratings, Availibility, rating_count, today]\n",
        "\n",
        "\n",
        "with open('Amazon_Web_Scraping_Dataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerow(data)"
      ],
      "metadata": {
        "id": "B8m40dtzyd8P"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Appending Data into CSV file."
      ],
      "metadata": {
        "id": "rPbygU_kQcf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we are appending data to the csv\n",
        "\n",
        "with open('Amazon_Web_Scraping_Dataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(data)\n"
      ],
      "metadata": {
        "id": "Z1GMm3L1CyJf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combining all of the data into one function to use it further."
      ],
      "metadata": {
        "id": "m2Ay_JQWQqQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine all of the above code into one function\n",
        "\n",
        "\n",
        "def check_price():\n",
        "    URL ='https://www.amazon.in/dp/8194790832/ref=s9_acsd_hps_bw_c2_x_3_i?pf_rd_m=A1K21FY43GMZF8&pf_rd_s=merchandised-search-7&pf_rd_r=QBKNEYYTKXJBNNPNE2G8&pf_rd_t=101&pf_rd_p=7482c79b-44d8-4499-93ae-28d5be5ebb9c&pf_rd_i=976389031'\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36\", \"Accept-Encoding\":\"gzip, deflate\",\"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\"DNT\":\"1\",\"Connection\":\"close\",\"Upgrade-Insecure-Requests\":\"1\"}\n",
        "    page = requests.get(URL, headers=headers)\n",
        "\n",
        "    soup1 = BeautifulSoup(page.content, \"lxml\")\n",
        "\n",
        "    soup2 = BeautifulSoup(soup1.prettify(), \"lxml\")\n",
        "\n",
        "\n",
        "\n",
        "    title = soup2.find(\"span\",attrs={\"id\":\"productTitle\"})\n",
        "    title_value = title.string\n",
        "    book_name = title_value.strip().replace(',','')\n",
        "    price = soup2.find(\"span\", attrs={\"class\":\"a-size-base a-color-price a-color-price\"}).string.strip().replace(',','')\n",
        "    Author = soup2.find(\"a\", attrs={\"data-asin\":\"B001HCYPOC\"}).string.strip().replace(',','')\n",
        "    ratings = soup2.find(\"span\", attrs={\"class\":\"a-icon-alt\"}).string.strip().replace(',','')\n",
        "    Availibility=soup2.find(\"span\", attrs={\"class\":\"a-size-medium a-color-success\"}).string.strip().replace(',','')\n",
        "    rating_count = soup2.find(\"span\",attrs={\"id\":\"acrCustomerReviewText\"}).string.strip().replace(',','')\n",
        "    import datetime\n",
        "\n",
        "    today = datetime.date.today()\n",
        "\n",
        "    import csv \n",
        "\n",
        "    header = ['Book Name', 'Price','Author','Ratings','Availibility','Rating Count', 'Date']\n",
        "    data = [book_name, price, Author, ratings, Availibility, rating_count, today]\n",
        "\n",
        "\n",
        "    with open('Amazon_Web_Scraping_Dataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "yLP4swNOCzr8"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}